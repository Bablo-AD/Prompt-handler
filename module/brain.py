import openai
import os


class chatgpt_api:
    """
    This class represents the brain API for interacting with the GPT-3.5-turbo model.
    """

    def __init__(self,api_key,temperature=0,model="gpt-3.5-turbo-0613"):
        """
        Initializes the brain API with the OpenAI API key.
        """
        self.api_key = api_key
        self.model = model
        
        self.temperature = temperature
        openai.api_key = self.api_key
        
    def get_completion_for_message(self, message, temperature=None):
        """
        Generates a completion for a given message using the GPT-3.5-turbo model.

        Args:
            message (list): List of messages representing the conversation history.
            temperature (float): Control the randomness of the output.

        Returns:
            str: The completion generated by the model.
            int: The number of tokens used by the completion.
        """
        if temperature is None:
            temperature = self.temperature
            
        completion = openai.ChatCompletion.create(
            model=self.model,
            messages=message,
            temperature=temperature
        )
        return completion.choices[0].message['content'], completion['usage']['prompt_tokens']
    
    def get_completion(self, message_history=None, message='', update_history=True, temperature=0):

        """
        Generates a completion for the conversation history.

        Args:
            message_history (message_history): The conversation history.
            message (str): The user's message to be added to the history.
            update_history (bool): Flag to update the conversation history.
            temperature (float): Control the randomness of the output.

        Returns:
            str: The completion generated by the model.
            int: The number of tokens used by the completion.
        """
        if message_history is None:
            message_history = self
        if message == '':
            completion_output = self.get_completion_for_message(message_history.messages, temperature)
            if update_history:
                message_history.add_assistant(completion_output[0])
                message_history.tokens = completion_output[1]
                return message_history.get_last_message()['content'], message_history.tokens
            else:
                return completion_output
        else:
            if update_history:
                message_history.add_user(message)
                completion_output = self.get_completion_for_message(message_history.messages, temperature)
                message_history.add_assistant(completion_output[0])
                message_history.tokens = completion_output[1]
                return message_history.get_last_message()['content'], message_history.tokens
            else:
                temporary_message = message_history.messages.copy()
                temporary_message.append({"role": "user", "content": message})
                completion_output = self.get_completion_for_message(temporary_message, temperature)
                return completion_output
    
    def converse(self, message_history=None, update_history=True, temperature=0):
        """
        Starts a conversation with the model.

        Args:
            message_history (message_history): The conversation history.
            update_history (bool): Flag to update the conversation history.
            temperature (float): Control the randomness of the output.
        """
        if message_history is None:
            message_history = self
        print(self.get_completion(message_history=message_history, update_history=update_history, temperature=temperature))
        while True:
            user_input = input()
            if user_input == '\\break':
                return message_history
            print(self.get_completion(message_history=message_history, message=user_input, update_history=update_history, temperature=temperature))
   